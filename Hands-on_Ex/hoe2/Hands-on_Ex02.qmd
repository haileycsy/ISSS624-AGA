---
title: "Hands-on Ex 2"
date: "Published on November 19 2023"
date-modified: "Last updated on `r format(Sys.time(), '%B %d %Y')`"
format:
  html:
    code-fold: true
    code-summary: "code block"
    toc-title: Contents
    number-sections: true
execute: 
  warning: false
---

# **Part 1**
<font size = "5">**Spatial Weights and Applications**</font>

A key aspect of spatial analysis is to measure the **strength of the spatial relationships between spatial objects, or how these related spatial objects influence each other.** This would allow us to further the analysis by computing spatial autocorrelation indices, implementing spatial econometrics techniques, studying the spatial distribution of observations, as well as performing spatial sampling or graph partitioning. Source: [Handbook of Spatial Analysis](https://www.insee.fr/en/information/3635545)

Computing **spatial weights and neighbor links** is a necessary part of this analysis process, and is the key focus of this exercise.

::: {.pinbox .solve data-latex="pin"}
**What are Spatial Weights?**

**Spatial weights** are one way to represent graphs in geographic data science and spatial statistics and are widely used to represent geographic relationships between the observational units in a spatial dataset.

-   Spatial weights often express our knowledge about spatial relationships. For example, proximity and adjacency are common spatial questions: *What neighborhoods are you surrounded by? How many gas stations are within 5 miles of my stalled car?*
-   Spatial questions target specific information about the spatial configuration of a specific target ("a neighborhood," "my stalled car") and geographically connected relevant sites ("adjacent neighborhoods", "nearby gas stations")
:::

# Installing R packages

```{r}
#| message: false
pacman::p_load(sf, spdep, tmap, tidyverse, knitr, kableExtra, urbnthemes, ggplot2)
```

# Scope of Study

Two datasets will be used in this exercise:

-   **Geospatial:** Hunan county boundary layer set in ESRI shapefile format
-   **Aspatial:** Hunan's 2012 local development indicators in csv format

## Loading the data

::: panel-tabset
## **Geospatial shapefile**

```{r}
hunan <- st_read(dsn = "data/geospatial", 
                 layer = "Hunan")
```

## **Aspatial csv**

```{r}
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")
```

## **Joining the datasets**

By performing a `left_join()`, the geospatial dataframe **hunan** will be updated with attribute fields of **hunan2012**

```{r}
hunan <- left_join(hunan, hunan2012) %>%
  select(1:4, 7, 15)
```
:::

```{r}
head(hunan,10) %>%
  kbl() %>%
  kable_styling(
    full_width = F, 
    bootstrap_options = c("condensed", "responsive"))
```

# Visualising Regional Development Indicators

**GDPPC** Refers to Gross Domestic Product per capita, which measures a country's economic output per person. To visualise the distribution of GDPPC as a cloropleth map, `qtm()` of **tmap** package can be used.

```{r}
# Basemap without GDPPC mapping 
basemap <- tm_shape(hunan) +
  tm_polygons() +
  tm_text("NAME_3", size = .5)

# Cloropleth map
gdppc <- qtm(hunan, "GDPPC")

#Place maps side-by-side
tmap_arrange(basemap, 
             gdppc, 
             asp = 1, 
             ncol = 2)
```

# The **neighborhood** in Spatial Analysis

An important concept in spatial analysis is that of a *neighborhood*, which refers to those data points that we consider to be proximate to a given focal data point. With area-based vector data (polygons), there are multiple ways to measure proximity:

-   **Contiguity-based neighbors** consider neighboring polygons to be those that "touch" a focal polygon, and are derived in **spdep** package with the `poly2nb()` function

-   **Distance-based neighbors** are those within a given proximity threshold to a focal polygon; distances are measured between polygon centroid using the `knn2nb()` function

![](images/spatial_relations.png)

To use this information in statistical analysis, it's often necessary to compute these relationships between all pairs of observations. This means building a topology ---- a mathematical structure that expresses the connectivity between observations ---- that we can use to examine the data. **A neighborhood matrix is a binary matrix that indicates whether pairs of locations are neighbors or not**, expressing this topology of relations with weights 1 and 0.


# Computing contiguity-based neighbors

Defining a neighbourhood in the sense of contiguity is often used to study demographic and social data, in which it may be more important to be on either side of an administrative boundary than to be located at a certain distance from one another.

::: {.pinbox .solve data-latex="pin"}
**Contiguity** happens when two spatial units share a common border.

-   **Queen Contiguity:** A neigboring polygon is one that shares a vertex with the focal polygon
-   **Rook Contiguity:** A neigboring polygon is one that shares an edge (line segment) with the focal polygon
:::

![](images/contiguity.png)

## Computing **Queen contiguity** based neighbours

The code chunk below computes a contiguity matrix based on Queen contiguity principle and returns a **neighbor list object**:

```{r}
#| code-fold: false
wm_q <- poly2nb(hunan, 
                queen = TRUE)
summary(wm_q)
```

::: {.focusbox .solve data-latex="focus"}
The summary report shows that:

-   There are 88 area units in Hunan
-   The most connected area unit has 11 neighbors (links)
-   The two least connected areas have only 1 neighbor
:::

::: panel-tabset
## **Listing specific neighbors**

For each polygon in our polygon object, `wm_q` lists all neighboring polygons. For example, to see the neighbors for polygon #1 in the object:

```{r}
#| code-fold: false
wm_q[[1]]
```

Polygon #1 has 5 neighbors.

## **Retrieving Country names by polygon \#**

We can retrieve the county name of Polygon ID=1 by using the code chunk below:

```{r}
#| code-fold: false
hunan$County[1]
```

To reveal the county names of the five neighboring polygons, the code chunk will be used:

```{r}
#| code-fold: false
hunan$NAME_3[c(2,3,4,57,85)]
```

## **Retrieving GDPCC of countries by polygon \#**

```{r}
#| code-fold: false
# Store all neighbor polygon IDs in new variable
nb1 <- wm_q[[1]]
# Replace polygon IDs in the variable with respective GDPPC
nb1 <- hunan$GDPPC[nb1]

nb1
```

The printed output above shows that the GDPPC of the five nearest neighbors based on Queen's method are 20981, 34592, 24473, 21311 and 22879 respectively.

### **Displaying complete matrix**

You can display the complete weight matrix by using `str()`

```{r}
#| code-fold: false
str(wm_q)
```
:::

## Creating **Rook** contiguity based neighbours

Compute the Rook contiguity matrix by altering `queen` argument of `poly2nb()` function to return a **neighbor list object**:

```{r}
#| code-fold: false
wm_r <- poly2nb(hunan, 
                queen = FALSE)
summary(wm_r)
```

::: {.focusbox .solve data-latex="focus"}
The summary report shows that:

-   There are 88 area units in Hunan
-   The most connected area unit has 10 neighbors (links)
-   The two least connected areas have only 1 neighbor
:::

# Visualising Contiguity 1

A connectivity graph takes a point and displays a line connecting to each neighboring point. The current geospatial dataset only has **polygons** at the moment, so we will need to compute **points** in order to make our connectivity graphs. The most typical method for this will be using **polygon centroids.**

::: panel-tabset
## **Step 1: Generate lon & lat values for each polygon centroid**

To get our **longitude** values we map the `st_centroid` function over the geometry column of us.bound and access the longitude value through double bracket notation \[\[\]\] and 1. This allows us to get only the longitude, which is the first value in each centroid.

```{r}
#| code-fold: false
longitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])
```

We do the same for latitude with one key difference. We access the second value per each centroid with \[\[2\]\].

```{r}
#| code-fold: false
latitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])
```

## **combine lon & lat values into single data object**

```{r}
#| code-fold: false
coords <- cbind(longitude, latitude)
```

Check the first few observations to see if things are formatted correctly:

```{r}
head(coords)
```
:::

## Plotting Queen contiguity as a map

```{r}
#| fig-width: 6
#| fig-height: 6
plot(hunan$geometry, 
     border = "#ABA9C3")
plot(wm_q, 
     coords, 
     pch = 20, 
     cex = .7, 
     add = TRUE, 
     col= "salmon"
     )
```

## Plotting Rook contiguity as a map

```{r}
#| fig-width: 6
#| fig-height: 6
plot(hunan$geometry, border="lightgrey")
plot(wm_r, 
     coords, 
     pch = 19, 
     cex = 0.6, 
     add = TRUE, 
     col = "#129490")
```

## Putting both maps together

```{r}
#| fig-width: 8
#| fig-height: 5
par(mfrow = c(1,2))

# Queen
plot(hunan$geometry, 
     border = "lightgrey")
plot(wm_q, 
     coords, 
     pch = 20, 
     cex = .7, 
     add = TRUE, 
     col = "salmon",
     main = "Queen Contiguity"
     )

# Rook
plot(hunan$geometry, border="lightgrey")
plot(wm_r, 
     coords, 
     pch = 19, 
     cex = 0.6, 
     add = TRUE, 
     col = "#129490",
     main = "Rook Contiguity")

```

# Computing distance-based neighbors

Several steps are needed to obtain a *distance threshold* or *cut-off distance* that will be used to **define neighbors** in the analysis. This `cut-off distance` is crucial for creating a **weight matrix** that reflects the spatial relationships between regions based on their proximity within this defined distance band.

## Defining cut-off distance

::: panel-tabset
## **Step 1: Create a list of neighbors**

-   `knearneigh(coords)` is used to find k nearest neighbors for each point in the spatial dataset defined by the `coords` variable. **Returns:** k-nearest neighbor object (kn object)

-   `knn2nb()` is then used to convert the k-nearest neighbor object (kn object) into a neighbors list (nb object). This nb object represents the spatial relationships between neighboring regions based on the k-nearest neighbors and returns a **neighbor list object**:

```{r}
#| code-fold: false
k1 <- knn2nb(knearneigh(coords))
k1
```

## **Step 2: Calculate distance using `nbdists()`**

-   `nbdists()` calculates the distances between neighboring regions defined by the neighbors list **k1**
-   The `longlat = TRUE` argument indicates that the distances should be calculated assuming longitude and latitude coordinates, and it returns the distances in kilometers
-   `unlist()` flattens the result, converting it from a list structure to a simple numeric vector

```{r}
#| code-fold: false
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
```

## **Step 3: Determine upper threshold**

```{r}
#| code-fold: false

summary(k1dists)
```

The summary report shows that **the largest first nearest neighbour distance is 61.79 km**, so using this as the upper threshold gives certainty that all units will have at least one neighbour.
:::

## Computing fixed distance weight matrix

This is done using `dnearneigh()`:

```{r}
#| code-fold: false
wm_d62 <- dnearneigh(
  coords, 
  # specify lower and upper distance bands
  0, 62, 
  longlat = TRUE)

wm_d62
```

::: {.focusbox .solve data-latex="focus"}
The summary report shows that:

-   There are 88 area units in Hunan
-   There are 324 links between regions that fall within the distance band of 0 - 62km
-   On average, each region has about 3-4 neighbors that fall within the distance band
:::

::: panel-tabset
## Content of `wm_d62` weight matrix

```{r}
#| code-fold: false
str(wm_d62)
```

## Structure of `wm_d62` weight matrix

Use a combination of`table()` and `card()` to return a **contingency matrix** of number of neighbors per country:

```{r}
#| code-fold: false
table(hunan$County, 
    # list number of neighbors for each area
      card(wm_d62))
```
:::

# Visualising Contiguity 2

```{r}
plot(hunan$geometry, border = "lightgrey")

plot(wm_d62, coords, add = TRUE)
plot(k1, coords, add = TRUE, col = "salmon", length = .08)
```

The red lines show the links of 1st nearest neighbours and the black lines show the links of neighbors within the cut-off distance of 62km.

```{r}
par(mfrow=c(1,2))
par(family = "mono")

plot(hunan$geometry, border="lightgrey")

plot(k1, coords, add=TRUE, col="salmon", length=0.08, main="1st nearest neighbours")
title("1st Nearest Neighbours")

plot(hunan$geometry, border="lightgrey")

plot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6, main="Distance links")
title("Distance Links")

```

# Computing Adaptive distance weight matrix

In fixed distance weight matrices, more densely populated areas (usually the urban areas) tend to have more neighbors and the less densely settled areas (usually the rural counties) tend to have fewer neighbors. Having many neighbors smoothes the neighbor relationship across more neighbors.

It is possible to control the numbers of neighbors directly using k-nearest neighbors, either accepting asymmetric neighbors or imposing symmetry -- stating `k = n` as a parameter where n = number of neighbors:

```{r}
#| code-fold: false

knn6 <- knn2nb(knearneigh(coords, k = 6))
knn6

```

```{r}
#| fig-width: 6

plot(hunan$geometry, border="#dfdfeb")

plot(knn6, 
     coords, 
     pch = 15, 
     cex = .6, 
     add = TRUE, 
     col = "#7F0799")
```

# Computing Inversed Distance Weights (IDW)

The **Inverse Distance** method assigns weights to neighboring locations based on the inverse of the distance between them. **The closer two locations are, the higher the weight assigned to their relationship.** In an IDW spatial weight matrix, regions that are closer to each other will have higher weights, indicating a stronger spatial relationship.

The following steps are taken to calculate the inverse of distances for each pair of neighboring regions based on a given spatial weight matrix **wm_q** and the corresponding spatial coordinates, **coords**.

::: panel-tabset 

## **Step 1: Compute Distances between areas**

This is done through `nbdists()` of spdep:

```{r}
# Calculate distance between points
dist <- nbdists(wm_q, coords, longlat = TRUE)

# Calculate the inverse distance of each element in dist
ids <- lapply(dist, function(x) 1/(x))
ids
```

# Weight Matrix Standardisation

The sum of the weights of the neighbors of a zone is called its *degree of connection*. Standardized matrices ensure that the degree of connection will depend on the number of its neighbours, which creates heterogeneity between the zones.

::: {.pinbox .solve data-latex="pin"}
**Types of Standardization:**

-   Row Standardization, "W"
-   Global Standardization, "C"
-   Uniform Standardization, "U"
-   Variance Stabilization, "S"
-   No Standardization, "B"

:::

In general, Row standardization gives more weight to observations bordering the study zone, with a small number of neighbors. In global or uniform standardization, the observations in the centre of the study zone with a large number of neighbors, and are thus subject to more external influences than the border zones. This heterogeneity can have a significant impact on the results of spatial autocorrelation tests.

## Row Standardization

Row-standardization involves dividing each weight in a row by the sum of weights in that row. This ensures that the weights for each observation (row) in the matrix sum to 1, making it a row-standardized spatial weight matrix.

Row-standardization helps to remove the influence of the number of neighbors each observation has, making the spatial weight matrix more comparable across different datasets or regions.

`nb2listw()` function converts a neighbors list object into a **weight list object**:

```{r}
#| code-fold: false
rswm_q <- nb2listw(wm_q, 
            # Specify spatial weights matrix
                   style = "W", 
            # regions with no neighbors are retained in matrix, weights set to zero
                   zero.policy = TRUE)
rswm_q
```

```{r}
summary(unlist(rswm_q$weights))
```
## Unstandardized weight matrix

**style = "B"** Creates a binary (unstandardized) **weight list object**:

```{r}
rswm_ids <- nb2listw(wm_q, glist = ids, style = "B", zero.policy = TRUE)
rswm_ids
```

```{r}
summary(unlist(rswm_ids$weights))
```

# Spatial lag variables

Spatial lag variables are used to account for spatial autocorrelation in the data, where the values of a variables in one location are influenced by the values of the variable in nearby locations. A spatially lagged variable is a weighted sum or a weighted average of the neighboring values for that variable where **Lag = E(x) or average value of the neighborhood**

::: {.pinbox .solve data-latex="pin"}
**Creating different spatially lagged variables:**

-   spatial lag with row-standardized weights
-   spatial lag as a sum of neighboring values
-   spatial window average
-   spatial window sum

:::

## Spatial lag with row-standardized weights

::: panel-tabset

## **Calculate variable spatial lag value**

The following code calculates the GDPPC Lag value, or average neighbor GDPPC value for each polygon and returns it as a **numeric vector:**

```{r}
#| code-fold: false
GDPPC_lag <- lag.listw(rswm_q, hunan$GDPPC)
GDPPC_lag 
```
## **Append values to main dataframe**

```{r}
#| code-fold: false
# create a list of Hunan provinces and corresponding spatial lag GDPPC values
lag_list <- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))

# Transform list into dataframe
lag_res <- as.data.frame(lag_list)

# Assign column names to dataframe
colnames(lag_res) <- c("NAME_3", "lag GDPPC")

# Join to main hunan dataframe
hunan <- left_join(hunan,lag_res)

head(hunan)
```
This reveals that `lag GDPPC` is stored as a new column in the **hunan** dataframe.

:::

**Comparing GDPPC and Spatial Lag GDPPC**

```{r}
# Plot normal GDPPC cloropleth map
gdppc <- qtm(hunan, "GDPPC")

# Plot lag GDPPC cloropleth map
lag_gdppc <- qtm(hunan, "lag GDPPC")

# Arrange in 2 columns
tmap_arrange(gdppc, lag_gdppc, asp = 1, ncol = 2)
```

## Spatial lag as a sum of neighboring values

Another way to calculate spatial lag is to sum neighboring values by assigning binary weights. 

## **Create binary spatial weights matrix**

```{r}
# For every neighbor an area has, assign value '1'
b_weights <- lapply(wm_q, function(x) 0*x +1)

# Create binary spatial weight matrix
b_weights2 <- nb2listw(wm_q, 
                       glist = b_weights, 
                       style = "B")

b_weights2

```

## **Compute Lag GDPPC**

```{r}
#| code-fold: false
# create a list of Hunan provinces and corresponding spatial lag GDPPC values
lag_sum <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))

# Transform list object into dataframe
lag_res <- as.data.frame(lag_sum)

# assign column names
colnames(lag_res) <- c("NAME_3", "lag_sum GDPPC")

# Append to hunan dataframe

hunan <- left_join(hunan, lag_res)
```
**Comparing GDPPC and Spatial Lag GDPPC**

```{r}
# original GDPPC Plot
gdppc <- qtm(hunan, "GDPPC")

# Lag sum GDPPC plot
lag_sum_gdppc <- qtm(hunan, "lag_sum GDPPC")

# Arrange side by side
tmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)
```

## Spatial window average

The spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.

::: panel-tabset

## **including self**

Using the `include.self()` method from **spdep** package modifies the existing spatial weights matrix such that each spatial unit is considered a neighbor to itself. Below is the neighbot list for polygon #1, which now has 6 neighbors instead of the original 5:

```{r}
wm_qs <- include.self(wm_q)
wm_qs[[1]]
```
## **Create Spatial weights List**

```{r}
wm_qs <- nb2listw(wm_qs)
wm_qs
```


## **Calculate spatial lag variable from new spatial weights list**

```{r}
lag_w_avg_gpdpc <- lag.listw(wm_qs, 
                             hunan$GDPPC)
lag_w_avg_gpdpc
```
## **Compute lag GDPPC**

```{r}
#| code-fold: false
# create a list of Hunan provinces and corresponding spatial lag GDPPC values
lag.list.wm_qs <- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))

# Transform list object into dataframe
lag_wm_qs.res <- as.data.frame(lag.list.wm_qs)

# Assign column names
colnames(lag_wm_qs.res) <- c("NAME_3", "lag_window_avg GDPPC")

# Add to main dataframe
hunan <- left_join(hunan, lag_wm_qs.res)
```

```{r}
head(hunan,10) %>%
  kbl() %>%
  kable_styling(
    full_width = F, 
    bootstrap_options = c("condensed", "responsive"))
```

:::

**Comparing lag GDPPC to window average Lag GDPPC**

```{r}
w_avg_gdppc <- qtm(hunan, "lag_window_avg GDPPC")
tmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)
```


## Spatial window sum

This is similar to the spatial window average, but without using row-standardized weights.

::: panel-tabset

## **including self**
Polygon #1 now has 6 neighbors instead of 5: 

```{r}
#| code-fold: false
wm_qs <- include.self(wm_q)
b_weights <- lapply(wm_qs, function(x) 0*x + 1)
b_weights[1]
```

## **Calculating Spatial Weights**

```{r}
#| code-fold: false
# Assign weights values
b_weights2 <- nb2listw(wm_qs, 
                       glist = b_weights, 
                       style = "B")
b_weights2
```

## **Compute lag value**

```{r}
# Compute lag value
w_sum_gdppc <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))

w_sum_gdppc.res <- as.data.frame(w_sum_gdppc)

colnames(w_sum_gdppc.res) <- c("NAME_3", "w_sum GDPPC")

hunan <- left_join(hunan, w_sum_gdppc.res)
```

```{r}
head(hunan,10) %>%
  kbl() %>%
  kable_styling(
    full_width = F, 
    bootstrap_options = c("condensed", "responsive"))
```

:::

**Comparing all the plots**

```{r}
#| fig-width: 8
#| warning: false

w_sum_gdppc <- qtm(hunan, "w_sum GDPPC")
tmap_arrange(gdppc, lag_gdppc, lag_sum_gdppc, w_avg_gdppc, w_sum_gdppc, 
             nrow = 2, asp = 1)

```


# **Part 2**
<font size = "5">**Global and Local Measures of Autocorrelation (GLISA)**</font>

One of the key questions for Geospatial Analysis is to uncover the geographical distribution of values across spatial areas. 
Given a set of areal features and an associated variable, 

-   **global** statistical tools evaluate whether the distribution of that variable follows a clustered, dispersed or random pattern
-   **local** indicators evaluate the existence of clusters in the spatial arrangement of that variable


# Global Measures of Spatial Autocorrelation

## **Global Moran's I**

::: panel-tabset

## **The Math**
Excerpt from [ArcGIS Pro](https://pro.arcgis.com/en/pro-app/3.1/tool-reference/spatial-statistics/h-how-spatial-autocorrelation-moran-s-i-spatial-st.htm)

The tool conducts the following calculations to derive an Index Value, Expected Index value, z-score and p-value:

1.  Compute the mean ($\mu$) and variance ($\sigma$) for the variable being evaluated
2.  For each feature value **x**, derive the *deviation from the mean* (**d**) where $d = x - \mu$
3.  Deviation values **d** of all neighboring areas are multiplied together to create a *cross-product*, **P**

If the values in the dataset tend to cluster spatially (high values cluster near other high values; low values cluster near other low values), the Moran's Index will be **positive**. When high values repel other high values, and tend to be near low values, the Index will be **negative**. If positive cross-product values balance negative cross-product values, the Index will tend towards **zero**. 

Given the number of features in the dataset and the variance for the data values overall, the tool computes a z-score and p-value indicating whether this difference is statistically significant or not. Index values cannot be interpreted directly; they can only be interpreted within the context of the null hypothesis. 


## **The Hypothesis**

As an inferential statistic, **Global Moran's I** tests the following hypothesis:

$$H_0: \text{The variable is randomly distributed among the spatial features in the study area}$$
$$H_1: \text{The variable is not randomly distributed among the spatial features in the study area}$$
Interpretation of statistical significance & distribution: 


|                                         | +ve Moran's I                                    | -ve Moran's I                                   |
|-----------------------------------------|--------------------------------------------------|-------------------------------------------------|
| **p-value < 0.05<br>(significant)**     | Reject $H_0$<br>Variable is Spatially Clustered  | Reject $H_0$<br>Variable is Spatially Dispersed |
| **p-value > 0.05<br>(Not significant)** | Accept $H_0$<br>Variable is randomly distributed                                                   |                                                                 |

## **The Test**

The code chunk below performs Moran’s I statistical testing using `moran.test()` of spdep:


```{r}
#| code-fold: false
moran.test(hunan$GDPPC, 
           listw = rswm_q, 
           zero.policy = TRUE, 
           na.action = na.omit)
```
From the test results, p-value is < 0.05, so we reject $H_0$ and conclude that the variable is not randomly distributed among the spatial features in the study area. The **alternative hypothesis: greater** indicates a positive spatial autocorrelation, suggestive of spatial clustering. 


## **Monte Carlo Moran**

The code chunk below performs a Monte Carlo simulation of n= 1000 trials for Moran’s I statistic by using `moran.mc()` of spdep:

```{r}
#| code-fold: false
set.seed(1234)

bperm <- moran.mc(hunan$GDPPC, 
                listw = rswm_q, 
                nsim = 999, 
                zero.policy = TRUE, 
                na.action = na.omit)
bperm
```

From the Monte Crlo simulation test results, p-value is < 0.05, so we reject $H_0$ and conclude that the variable is not randomly distributed among the spatial features in the study area. The **alternative hypothesis: greater** indicates a positive spatial autocorrelation, suggestive of spatial clustering. 

:::

### Visualising the results of Monte Carlo Moran's I Test

```{r}
# Extract result
sim_moran <- bperm$res
# Calculate mean result
sim_mean <- mean(sim_moran)

set_urbn_defaults(style = "print")

ggplot(
    data = data.frame(sim_moran),
    aes(x = sim_moran)
  ) +
  geom_histogram(
    bins = 30, 
    color = "#FFFCF9", 
    fill = "#1F363D",
    alpha = .8
  ) +
  # Add mean line
  geom_vline(
    xintercept = sim_mean, 
    color = "salmon", 
    linetype = "dashed", 
    linewidth = 1
  ) +
  # Add line annotations
  annotate(
    "text", 
    x = .035, 
    y = 100, 
    label = paste("Mean value =", round(sim_mean, 3)),
    color = "salmon",
    size = 3
  ) +
  labs(
    title = "Simulated Moran's I Statistic",
    subtitle= "(Based on Monte-carlo Simulation of 1000 trials)",
    x = "Moran's I Statistic",
    y = "Frequency"
  ) +
  theme(
    panel.grid.major = element_blank()
  )
```

## **Geary's C test**

Both Moran's I and Geary's C are measures of spatial autocorrelation. However, Geary's C calculation is a simpler calculation, taking the ratio of the sum of squared differences between neighboring values over the total variance. Their result statistics are also inversely related:

-   C value **close to 1** indicates **no spatial autocorrelation**
-   C value **nearer to 0** indicates **positive spatial correlation**
-   C value **nearer to 2** indicates **negative spatial correlation**

::: panel-tabset

## **The Test**

The code chunk below performs Geary’s C test for spatial autocorrelation by using `geary.test()` of spdep

```{r}
geary.test(hunan$GDPPC, listw = rswm_q)
```
From the test results, p-value is < 0.05, so we reject $H_0$ and conclude that the variable is not randomly distributed among the spatial features in the study area. The expected value under spatial randomness (1.0000000) is greater than the observed Geary C statistic (0.6907223), suggesting a spatial pattern of dissimilarity, where dissimilar values are clustered together.


## **Monte Carlo Geary's**

The code chunk below performs a Monte Carlo simulation of n= 1000 trials for Geary's C statistic by using `geary.test()`:

```{r}
#| code-fold: false
set.seed(1234)
gperm <- geary.mc(hunan$GDPPC, 
                  listw = rswm_q, 
                  nsim = 999)
gperm
```
From the test results, p-value is < 0.05, so we reject $H_0$ and conclude that the variable is not randomly distributed among the spatial features in the study area. The alternative hypothesis is stated as "greater", suggesting that the observed Geary C statistic is larger than expected under the assumption of spatial randomness, indicating a tendency for dissimilar values to be close to each other. 

:::

### Visualising the results of Monte Carlo Geary C's Test

```{r}
# Extract result
sim_geary <- gperm$res
# Calculate mean result
sim_g_mean <- mean(sim_geary)

set_urbn_defaults(style = "print")

ggplot(
    data = data.frame(sim_geary),
    aes(x = sim_geary)
  ) +
  geom_histogram(
    bins = 25, 
    color = "#FFFCF9", 
    fill = "#858AE3",
    alpha = .8
  ) +
  # Add mean line
  geom_vline(
    xintercept = sim_g_mean, 
    color = "#3A435E", 
    linetype = "dashed", 
    linewidth = 1
  ) +
  # Add line annotations
  annotate(
    "text", 
    x = .95, 
    y = 115, 
    label = paste("Mean value =", round(sim_g_mean, 3)),
    color = "#3A435E",
    size = 3
  ) +
  labs(
    title = "Simulated Geary's C Statistic",
    subtitle= "(Based on Monte-carlo Simulation of 1000 trials)",
    x = "Geary's C Statistic",
    y = "Frequency"
  ) +
  theme(
    panel.grid.major = element_blank()
  )
```

## Statistical results as correlograms

::: panel-tabset

## **Moran's I correlogram**

In the code chunk below, `sp.correlogram()` is used to compute a 6-lag spatial correlogram of GDPPC using global spatial autocorrelation Moran's I (`method = "I"`):

```{r}
#| code-fold: false
MI_corr <- sp.correlogram(wm_q, 
                          hunan$GDPPC, 
                          order = 6, 
                        # Use Moran's I Statistic
                          method = "I", 
                          style = "W")
plot(MI_corr)
```
Plotting the output may not provide a complete interpretation, because **not all autocorrelation values are statistically significant.** Hence, it is important for us to examine the full analysis report by printing out the analysis results:

```{r}
print(MI_corr)
```
::: {.solvebox .solve data-latex="solve"}

The results table has multiple columns. Each row corresponds to a specific lag distance.

-   **Estimate:** The observed Moran's I statistic at each lag distance.
-   **Expectation:** The expected Moran's I under the assumption of spatial randomness.
-   **Variance:** The variance of the Moran's I statistic.
-   **Standard Deviate:** The standard deviate of the observed Moran's I, indicating how many standard deviations the observed value is from the expected value under spatial randomness.
-   **Pr(I):** The p-value associated with the observed Moran's I.
-   **Two-sided:** Significance codes indicating the level of significance. Smaller p-values correspond to more asterisk, indicating significance. 

:::

## **Geary's C correlogram**

`method = "C"` uses Geary's C Statistic instead:

```{r}
#| code-fold: false
GC_corr <- sp.correlogram(wm_q, 
                          hunan$GDPPC, 
                          order = 6, 
                          method  ="C", 
                          style = "W")
plot(GC_corr)
```
```{r}
print(GC_corr)
```

:::

