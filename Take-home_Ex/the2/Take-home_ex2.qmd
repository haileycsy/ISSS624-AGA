---
title: "Take-home Ex 2"
date: "Published on December 7 2023"
date-modified: "Last updated on `r format(Sys.time(), '%B %d %Y')`"
format:
  html:
    code-fold: false
    code-summary: "code block"
    toc-title: Contents
    number-sections: true
execute: 
  warning: false
---

<font size = "5">{{< fa train-subway >}} Singapore MRT commuter flows</font>

# Project Brief

As city-wide urban infrastructure such as public buses, mass rapid transit, public utilities and roads become digital, the data sets obtained can be used for tracking movement patterns through space and time. This is particularly true with the recent trends in massive deployment of pervasive computing technologies such as GPS on vehicles and SMART cards used by public transport commuters.

Unfortunately, this explosive growth of geospatially-referenced data has far outpaced the planner's ability to utilize and transform the data into insightful information. There has not been significant practice research carried out to show how these disparate data sources can be integrated, analysed, and modelled to support policy making decisions, and a general lack of practical research to show how geospatial data science and analysis (GDSA) can be used to support decision-making.

This study aims to demonstrate the potential value of GDSA to integrate publicly available data from multiple sources for building spatial interaction models to **determine factors affecting urban mobility patterns in public bus transit.**

# Loading Required packages

The following packages are used in this exercise:

-   **tmap** for cartography
-   **mapview** for interactive map backgrouds & **leaflet.providers** for basemap customisation
-   **sf** for geospatial data handling
-   **stplanr** for creating 'desire lines'
-   **tidyverse** for aspatial data transformation
-   **sfdep** and **spdep** for computing spatial autocorrelation
-   **Hmisc** for summary statistics
-   **kableExtra** and **DT** for formatting of dataframes
-   **ggplot2, patchwork** and **ggrain** for visualising attributes
-   **urbnthemes** for consistent plot theming

```{r}
options(repos = c(CRAN = "https://cran.rstudio.com/"))

pacman::p_load(tmap, sf, tidyverse, sfdep, stplanr,
               mapview, leaflet.providers,
               Hmisc, kableExtra, DT, 
               ggplot2, patchwork, ggrain, urbnthemes, knitr)
```

# Importing the Data

## Aspatial Data

This study uses 2 aspatial datasets:

-   **train**, a dataset from [LTA Datamall](https://www.waterpointdata.org/access-data/), *Passenger Volume by Origin Destination Train Stations* for October 2023.
-   **train_codes**, also from LTA Datamall, lists train station codes and names. This is used to assign MRT train station codes to the geospatial data set with train station locations. 
-   **hdb**, a HDB Property Information dataset from data.gov.sg (updated in June 2023)

::: panel-tabset
## **train**

The downloaded dataset is in **.csv** format. We use the function `read_csv()` to import the data into the R environment.

```{r}
#| message: false
train_oct23 <- read_csv("data/aspatial/origin_destination_train_202310.csv")

# remove any duplicated rows
train_oct23 <- distinct(train_oct23)

str(train_oct23)
```

**train_oct23** is a tibble dataframe consisting of the following variables:

-   **YEAR_MONTH**: Month of data collection in YYYY-MM format
-   **DAY_TYPE**: Category of Day
-   **TIME_PER_HOUR**: Extracted hour of day
-   **PT_TYPE**: Public transport type
-   **ORIGIN_PT_CODE**: ID of Trip Origin Train Station
-   **DESTINATION_PT_CODE**: ID of Trip Destination Train Station
-   **TOTAL_TRIPS**: Sum of trips made per origin-Destination

```{r}
Hmisc::describe(train_oct23)
```

::: {.pinbox .solve data-latex="pin"}
**From the summary statistics above, we can derive that:**  

- There are **800,959** Origin-Destination (OD) trips made in October 2023 
- Data is collected for 24 hours, starting from 0 Hrs to 23 Hrs in **TIME_PER_HOUR** 
- The highest number of trips for an OD route is **21,050**, while the 95th Percentile is only **455**. This suggests a highly right-skewed distribution, with particularly busy routes.  


:::  

As we are interested in studying the passenger flows for **peak hour periods** only, the number of trips are calculated for each period as defined below:

| Peak Period        | Tap in Time (hr) |
|--------------------|------------------|
| Weekday Morning    | 6 - 9            |
| Weekday Evening    | 17 - 20          |
| Weekend/PH Morning | 11 - 14          |
| Weekend/PH Evening | 16 - 19          |  


The dataframe now shows the traffic volume by peak period for each Origin-Destination route: 

```{r}
#| code-fold: true

train_od <- train_oct23 %>%
   # Categorize trips under period based on day and timeframe
  mutate(period = ifelse(DAY_TYPE == "WEEKDAY" & 
                         TIME_PER_HOUR >= 6 & TIME_PER_HOUR <= 9, 
                         "Weekday morning peak",
                    ifelse(DAY_TYPE == "WEEKDAY" & 
                           TIME_PER_HOUR >= 17 & TIME_PER_HOUR <= 20,
                           "Weekday evening peak",
                      ifelse(DAY_TYPE == "WEEKENDS/HOLIDAY" &
                             TIME_PER_HOUR >= 11 & TIME_PER_HOUR <= 14,
                              "Weekend/PH morning peak",
                        ifelse(DAY_TYPE == "WEEKENDS/HOLIDAY" & 
                              TIME_PER_HOUR >= 16 & TIME_PER_HOUR <= 19,
                               "Weekend/PH evening peak",
                    "Others"))))
  ) %>%
  # Only retain needed periods for analysis
  filter(
    period != "Others"
  ) %>%
 # compute number of trips per origin busstop per month for each period
  group_by(
    ORIGIN_PT_CODE,
    DESTINATION_PT_CODE,
    period
  ) %>%
  summarise(
    num_trips = sum(TOTAL_TRIPS)
  ) %>%
  # change all column names to lowercase
  rename_with(
    tolower, everything()
  ) %>%
  ungroup()

DT::datatable(head(train_od,20))
```

::: {.cautionbox .solve data-latex="caution"}

There are several instances where **ORIGIN_PT_CODE** and **DESTINATION_PT_CODE** are not composite codes, representing MRT Stations that are **interchanges** with multiple station lines. For the purpose of this investigation, only a single station code is required. 

:::

```{r}
train_od <- train_od %>%
  separate_wider_delim(origin_pt_code,
                       delim = "/", 
                       names = c("origin_station_code", "unused_origin"),
                    # to capture first station for those without multiples
                       too_few = "align_start",
                    # to remove any other unused station columns for 3 or more
                       too_many = "drop"
  ) %>%
  separate_wider_delim(destination_pt_code,
                       delim = "/", 
                       names = c("dest_station_code", "unused_dest"),
                       too_few = "align_start",
                       too_many = "drop"
  ) %>%
  select(
    origin_station_code,
    dest_station_code,
    period,
    num_trips
  )
```



## **train_codes**

This dataset lists train station codes and names. It is used to join with the geospatial dataset for station identification. 

```{r}
train_codes <- read_csv("data/aspatial/train_codes.csv")

str(train_codes)
```


## **hdb**

The dataset is also in **.csv** format:

```{r}
hdb <- read_csv("data/aspatial/hdb.csv")

# Remove any duplicated rows
hdb <- distinct(hdb)

str(hdb)
```

**hdb** is a geocoded list of HDB properties in Singapore, with information such as:

-   **blk_no** & **street**: Address of the HDB Property
-   **max_floor_lvl** & **year_completed**: Characteristics of the HDB building, indicative of height and age
-   **residential**, **commercial**, **market_hawker**, **miscellaneous**, **multistorey_carpark** & **precinct_pavilion** , a series of boolean columns indicating if the HDB Property has the facilities
-   **bldg_contract_town**: A code indicating HDB town
-   **total_dwelling_units**: Number of units in the block
-   **xx_sold** & **xx_rental**: multiple columns indicating number of units sold and rented per type
-   **lat** & **lng**: Geocoded lattitude and longitudinal data pertaining to HDB location
-   **SUBZONE**: Subzone information

```{r}
summary(hdb)
```
:::

# {{< fa train-subway >}} **What is the Distribution of Passenger Traffic across peak periods?**

To determine which time period to analyze further, we visualize the distribution of trips by peak period:

```{r}
#| code-fold: true
#| fig-width: 8
set_urbn_defaults(style = "print")

trip_density <- train_od %>%
  ggplot(
    aes(x = period,
        y = num_trips,
        fill = period,
        color = period)
  ) +
  geom_violin(
    # shift violin plot upwards
    position = position_nudge(x = .3, y = 0), alpha = .8
  ) +
  geom_point(
    aes(y = num_trips,
        color = period),
    position = position_jitter(width = .15),
    size = .5,
    alpha = 0.8
  ) +
  labs(
    title = "Oct 2023: Widest range of MRT trips during Weekday Evening Peak"
  ) + 
  theme(
    axis.title.y = element_blank(),
    axis.title.x = element_blank(),
    axis.ticks.y = element_blank(),
    axis.ticks.x = element_blank(),
    legend.position = "none"
  ) +
  coord_flip()

trip_density

```  

The density plot reveals a highly right-skewed distribution for all trips, especially during **weekday evening peak periods**. This could point towards congested MRT train stations, and would be useful to analyse further to determine the possible factors leading to this high passenger volume. 

The OD data for weekday evening peak periods will thus be the focus of the study, and data is extracted using the following code chunk:

```{r}

weekday_pm_od <- train_od %>%
  filter(period == "Weekday evening peak")

write_rds(weekday_pm_od, "data/rds/weekday_pm_od.rds")
```



## Geospatial Data

The following geospatial dataframes are used for this exercise:

-   **train_station**, the location of train stations (*RapidTransitSystemStation*) from LTA Datamall
-   **Business**, **entertn**, **fnb**, **finserv**, **recreation** and **retail**, geospatial data sets of the locations of business establishments, entertainments, food and beverage outlets, financial centres, leisure and recreation centres, retail and services stores/outlets I compiled for urban mobility study

## Preparing Geospatial Files: train station

As the files are all based on Singapore Maps, they are in SVY21 coordinate reference system (CRS) and projected in ESPG code 3414 using `st_transform()`

::: panel-tabset

## **loading train_station**

**train_station** is a Simple feature **polygon** layer based on SVY21 coordinate reference system (CRS).

```{r}
train_station <- st_read(dsn = "data/geospatial",
                         layer = "RapidTransitSystemStation") %>%
          st_transform(crs = 3414)
```  

::: {.cautionbox .solve data-latex="caution"}
**Dataset limitations**

-   **train_station** only lists the Type of station (MRT or LRT), Station name and geolocation of each station. There is no station code to join with the aspatial dataset. Thus, the use of **train_codes** is needed to assign a unique train code identifier to each station  

-   There are only **203** Station codes in **train_codes**, compared to **220** entries in **train_station**. There may be duplicated station names, which needs further investigation. 

- *GDAL Message 1: Non closed ring detected* -- This warning message was received when loading in the geospatial layer. This means that there are polygons that are not closed (starting and ending points are not joined). There is a need for further geospatial data wrangling to rectify this. 


:::


## {{< fa wrench >}} **Removing duplicates**

Checking for duplicated station entires in **train_station**:

```{r}

train_duplicates <- train_station %>%
  # remove geometry layer
  st_set_geometry(NULL) %>%
  group_by(TYP_CD_DES,
           STN_NAM_DE
  ) %>%
  # count number of rows per train station
  summarise(
    count = n()
  ) %>%
  ungroup() %>%
  # retrieve stations with more than single row
  filter(count > 1)

DT::datatable(train_duplicates)
```  

The code above reveals that there are several entries for the stations above in **train_station**. This may be due to the fact that some stations are **interchanges** and have multiple train lines. However, there is no way to differentiate this without station code, and this study will assume that the location of these stations are within the same boundary anyway. Only one geospatial entry per station is selected using `slice()`:

```{r}

# Remove duplicates on selected columns
train_station <- train_station %>%
  group_by(STN_NAM_DE) %>%
  slice(1) %>%
  st_as_sf()
```


## {{< fa wrench >}} **Cleaning up station names**

As **train_station** does not have station codes that may be joined to the OD dataset for analysis, it is joined to **train_codes** by train station name. However, the station names in **train_codes** are in lowercase and without the suffix "MRT STATION" in the station names -- there is thus an extra layer of data wrangling to be done before joining. 

```{r}

train_codes_new <- train_codes %>%
  # Assign suffix to train station names and change to upper case
  mutate(station_name = ifelse(type == "MRT", 
                               paste0(toupper(mrt_station_english), " MRT STATION"),
                               paste0(toupper(mrt_station_english), " LRT STATION"))
  )
```


## {{< fa wrench >}} **Joining station names to get station codes**

The code chunk below assigns train station code to the geospatial layer to identify each station by code. 

```{r}

train_station_comb <- train_station %>%
  left_join(train_codes_new,
            by = join_by(STN_NAM_DE == station_name,
                         TYP_CD_DES == type)
  ) %>%
  select(
    stn_code,
    STN_NAM_DE,
    TYP_CD_DES
  )
```

There are several stations that have no **stn_code**:

```{r}
#| code-fold: true

train_station_comb %>%
  filter(is.na(stn_code)) %>%
  datatable()
```

As these are mainly train depots that are not identified by code and irrelvant to analysis of OD flows, these are removed from the dataset and saved as a new file, **train_station_list**:

```{r}
#| eval: false
train_station_list <- train_station_comb %>%
  filter(!is.na(stn_code))

```


## {{< fa wrench >}} **Checking geometry layer**

We use `st_is_valid()` to retrieve the invalid polygon datapoints in **train_station_list**:

```{r}
#| eval: false
# Retrieve invalid geometries
invalid_indices <- which(!st_is_valid(train_station_list))
invalid_indices
```
The code chunk above reveals that **index 195** is invalid. This is identified as **UPPER THOMSON MRT STATION**:

```{r}
#| eval: false
train_station_list[195,]
```
To rectify this invalid geometry, use `st_make_valid()`:

```{r}
#| eval: false
train_station_valid <- st_make_valid(train_station_list)
```


Check validity of the geometry layer again:

```{r}
#| eval: false
invalid_indices2 <- which(!st_is_valid(train_station_valid))
invalid_indices2
```  

The code chunk shows that there are no more invalid geometries in the file. {{< fa face-smile >}}

```{r}
#| eval: false
# Save as file 
write_rds(train_station_valid, "data/rds/train_station_valid.rds")
```

:::

```{r}
#| code-fold: true

train_station_valid <- read_rds("data/rds/train_station_valid.rds")

tmap_mode("view")

tm_basemap("OneMapSG.Grey") +
tm_shape(train_station_valid) +
  tm_dots()

```

## {{< fa wrench >}} **Creating hexagon grid**

From the mapview above, the current simple features dataframe only shows the train stations as points on the map, which not suitable for understanding commuter flows between areas. In urban transportation planning, **Traffic Analysis Zones (TAZ)** are the basic units of spatial areas delineated to tabulate traffic-related models. 

The following code chunks create a **hexagonal grid frame** spanning 700m between edges for each hexagon:

::: panel-tabset

## **Step 1: make hexagon grid**

```{r}
# create hexagon frame
train_hex <- st_make_grid(
    train_station_valid, 
    # for hexagonal cells, cellsize = the distance between opposite edges
    cellsize = 750, 
    square = FALSE
  ) %>%
  st_sf() %>%
  rowid_to_column("hex_id")
```

This creates a hexagonal grid over the entire area:

```{r}
#| code-fold: true
tmap_mode("plot")
qtm(train_hex)
```

## **Step 2: Retrieve stations per hexagon TAZ**

```{r}
# join to train station names
train_stops <- st_join(
    train_station_valid,
    train_hex,
    join = st_intersects
  ) %>%
  st_set_geometry(NULL) %>%
  group_by(stn_code) %>%
  summarise(
  # Ensure that each station gets assigned to a single hex_id
    hex_id = first(hex_id)
  ) %>%
  ungroup() %>%
  group_by(hex_id) %>%
  summarise(
    station_count = n(),
    station_codes = str_c(stn_code, collapse = ","),
  ) %>%
  ungroup()
```

## **Step 3: Create sf dataframe unique at hex_id**

```{r}
train_hex_final <- train_hex %>%
  left_join(train_stops,
          by = "hex_id"
  ) %>%
  replace(is.na(.), 0)
```

:::

```{r}
#| code-fold: true

# Get hexagons with at least one station 
train_hex_filtered <- train_hex_final %>%
  filter(station_count > 0)

tmap_mode("view")


tm_basemap("OneMapSG.Grey") +
  tm_shape(train_hex_filtered) +
  tm_fill(
    col = "station_count",
    palette = "-RdYlGn",
    style = "cont",
    id = "hex_id",
    popup.vars = c("No. of Train Stations: " = "station_count",
                   "Train station codes: " = "station_codes"),
    title = " "
  ) +
  tm_layout(
    # Set legend.show to FALSE to hide the legend
    legend.show = FALSE
  )
```


# {{< fa train-subway >}} **Which trips are the most congested on Weekday Evening Peaks?**

We seek to understand the inter-zone trip volume per TAZ, to understand which routes are the most popular during weekday evening peak periods. 


## Preparing Origin-Destination flow data

The following steps are done to prepare O-D flow dataframes at hexagon level:

::: panel-tabset

## **Extract Station codes & hex_ids**

```{r}
#| eval: false
station_by_hex <- train_hex_final %>%
  select(
    hex_id,
    station_codes
  ) %>%
  st_drop_geometry() %>%
  # create separate rows for each hex_id - station_code pair
  separate_rows(station_codes, 
                sep = ","
  ) %>%
  # drop any hexagon without stations
  filter(station_codes != 0)
```


## **Get trip origin hex_ids**

```{r}
#| eval: false
od_data <- left_join(
    weekday_pm_od, 
    station_by_hex,
    by = c("origin_station_code" = "station_codes")
  ) %>%
  rename(
    origin_stn = origin_station_code,
    origin_hex = hex_id,
    dest_stn = dest_station_code
  ) %>%
  distinct()
```


## **Get trip destination hex_ids**

```{r}
#| eval: false
od_data <- left_join(
    od_data,
    station_by_hex,
    by = c("dest_stn" = "station_codes")
  ) %>%
  rename(
    dest_hex = hex_id
  ) %>%
  group_by(
    origin_hex,
    dest_hex
  ) %>%
  summarise(
    weekday_pm_trips = sum(num_trips)
  ) %>%
  ungroup()
```
## **(Optional) Save file as RDS for future use**

```{r}
#| eval: false
write_rds(od_data, "data/rds/od_data.rds")
```

:::

## Visualising Spatial Interation 

The following steps are taken to visualise the traffic flows between TAZs. 

## **Remove intra-zonal flows**

As we are only interested in inter-zonal flows, we remove the intra-zonal trips from **od_data** dataframe:

```{r}
od_data <- read_rds("data/rds/od_data.rds")

od_data_inter <- od_data[od_data$origin_hex!=od_data$dest_hex,]
```

## **Create Desire lines**

**Desire lines** are straight lines that connect origin to destination. `od2line() ` function is used to create these:

```{r}
od_flow <- od2line(flow = od_data_inter, 
                    zones = train_hex_filtered,
                    zone_code = "hex_id")
```
## **Distribution of OD flows**

`quantile()` reveals that there is a large range between 75% and 100% quantiles. This will affect the visualisation of OD flows. 


```{r}
quantile(od_flow$weekday_pm_trips)
```
:::


```{r}
#| code-fold: true
#| fig-width: 8

tmap_options(check.and.fix = TRUE)
tmap_mode("plot")

tm_shape(train_hex_filtered) +
  tm_fill(
    col = "station_count",
    palette = "-RdYlGn",
    alpha = .7,
    style = "cont",
    # set legend title
    title = "Station Count"
  ) +
od_flow %>% 
  filter(weekday_pm_trips > 10000) %>%
tm_shape() +
  tm_lines(
    lwd = "weekday_pm_trips",
    style = "cont",
    n = 6,
    col = "#451F55",
    alpha = .5
  ) +
  tm_layout(
    title = "Weekday Evening Peak Traffic Flow",
    scale = .9,
    legend.stack = "horizontal",
    legend.position = c("left", "bottom"),
    frame = FALSE
  ) +
  tmap_style("classic")
```





## business

**business** is a Simple feature **point** layer based on SVY21 coordinate reference system (CRS).

```{r}
business <- st_read(dsn = "data/geospatial",
                    layer = "Business") %>%
          st_transform(crs = 3414)
```

## entertainment

**entertn** is a Simple feature **point** layer based on SVY21 coordinate reference system (CRS).

```{r}
entertn <- st_read(dsn = "data/geospatial",
                    layer = "entertn") %>%
          st_transform(crs = 3414)
```

## food & beverage

**fnb** is a Simple feature **point** layer based on SVY21 coordinate reference system (CRS).

```{r}
fnb <- st_read(dsn = "data/geospatial",
               layer = "F&B") %>%
          st_transform(crs = 3414)
```

## financial services

**finserv** is a Simple feature **point** layer based on SVY21 coordinate reference system (CRS).

```{r}
finserv <- st_read(dsn = "data/geospatial",
                  layer = "FinServ") %>%
          st_transform(crs = 3414)
```

## recreational facilities

**recreation** is a Simple feature **point** layer based on SVY21 coordinate reference system (CRS).

```{r}
recreation <- st_read(dsn = "data/geospatial",
                      layer = "Liesure&Recreation") %>%
          st_transform(crs = 3414)
```

## retail establishments

Finally, **retail** is a Simple feature **point** layer based on SVY21 coordinate reference system (CRS).

```{r}
retail <- st_read(dsn = "data/geospatial",
                  layer = "Retails") %>%
          st_transform(crs = 3414)
```
:::

# Data Preparation

As **train_station** is a spatial point layer that is not particularly useful for spatial analysis, we create a hexagonal spatial polygon layer to represent the traffic analysis zone (TAZ)

::: panel-tabset

## Create hexagon grid frame


